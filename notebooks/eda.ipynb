{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from morty.config import ConfigManager\n",
    "from rock_paper_scissors import get_dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ConfigManager({\n  \"seed\": 63815329,\n  \"train_dataset_path\": \"data/rps-webcam-val-dataset/\",\n  \"val_dataset_path\": \"data/webcam/\",\n  \"test_dataset_path\": \"data/webcam_test/\",\n  \"image_size\": [\n    300,\n    300\n  ],\n  \"num_classes\": 3,\n  \"epochs\": 50,\n  \"batch_size\": 32,\n  \"learning_rate\": 0.001,\n  \"feature_extractor\": \"MobileNetV2\",\n  \"train_augmentation\": \"Compose([\\n  VerticalFlip(always_apply=False, p=0.5),\\n  HorizontalFlip(always_apply=False, p=0.5),\\n  RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.1, 0.1), brightness_by_max=False),\\n  HueSaturationValue(always_apply=False, p=1.0, hue_shift_limit=(-20, 20), sat_shift_limit=(-30, 30), val_shift_limit=(-20, 20)),\\n  GaussNoise(always_apply=False, p=1.0, var_limit=(10.0, 50.0)),\\n  MotionBlur(always_apply=False, p=1.0, blur_limit=(3, 6)),\\n  CoarseDropout(always_apply=False, p=0.8, max_holes=50, max_height=10, max_width=10, min_holes=20, min_height=8, min_width=8, fill_value=0, mask_fill_value=None),\\n  ImageCompression(always_apply=False, p=0.5, quality_lower=80, quality_upper=100, compression_type=0),\\n  ISONoise(always_apply=False, p=1.0, intensity=(0.1, 0.5), color_shift=(0.01, 0.05)),\\n], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\",\n  \"validation_augmentation\": \"Compose([\\n], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\",\n  \"config_file\": \"configs/basic_config\"\n})\n"
     ]
    }
   ],
   "source": [
    "config = ConfigManager(config_path='configs', config_name='basic_config', console_args={})\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Dataset: {'rock': 956, 'paper': 969, 'scissors': 923, 'total': 2848}\n"
     ]
    }
   ],
   "source": [
    "train_stats = get_dataset_stats(config.train_dataset_path)\n",
    "\n",
    "print('Train Dataset: {}'.format(train_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WebCam Train Dataset: {'rock': 116, 'paper': 129, 'scissors': 83, 'total': 328}\n"
     ]
    }
   ],
   "source": [
    "webcam_train_stats = get_dataset_stats('./data/webcam_val/')\n",
    "\n",
    "print('WebCam Train Dataset: {}'.format(webcam_train_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WebCam Val Dataset: {'rock': 112, 'paper': 142, 'scissors': 206, 'total': 460}\n"
     ]
    }
   ],
   "source": [
    "webcam_val_stats = get_dataset_stats('./data/webcam/')\n",
    "\n",
    "print('WebCam Val Dataset: {}'.format(webcam_val_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WebCam Test Dataset: {'rock': 50, 'paper': 77, 'scissors': 52, 'total': 179}\n"
     ]
    }
   ],
   "source": [
    "webcam_test_stats = get_dataset_stats('./data/webcam_test/')\n",
    "\n",
    "print('WebCam Test Dataset: {}'.format(webcam_test_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}